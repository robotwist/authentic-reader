# Llama Service Configuration

# Ollama host URL
OLLAMA_HOST=http://localhost:11434

# Model configuration
LLAMA_MODEL=llama3:8b
FALLBACK_MODEL=llama2:7b-chat

# Cache settings
CACHE_SIZE=1000
CACHE_TTL=3600

# Logging configuration
LOG_LEVEL=INFO

# Server settings
PORT=3500
HOST=0.0.0.0 